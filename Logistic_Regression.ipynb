{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        "Answer:\n",
        "Logistic Regression is a type of regression model that is used when the output variable is categorical (like yes/no, 0/1, true/false). Instead of predicting continous values like linear regression, it predicts probability of a class. The probability is then mapped into 0 or 1 using a threshold (mostly 0.5).\n",
        "\n",
        "Linear regression draws a straight line and is used for continous values like salary prediction, house price etc. Logistic regression on the other hand uses sigmoid curve and works for classification problems.\n",
        "\n",
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "Answer:\n",
        "The sigmoid function takes any real number input and squashes it between 0 and 1. This is perfect for logistic regression because we want to predict probability of a class.\n",
        "Formula: 1 / (1 + e^-z)\n",
        "\n",
        "If output is close to 0 → model predicts class 0.\n",
        "If output is close to 1 → model predicts class 1.\n",
        "So basically sigmoid helps to convert linear combination into probability.\n",
        "\n",
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "Answer:\n",
        "Regularization is a technique to avoid overfitting of the model. In logistic regression, sometimes coefficients (weights) become too large which makes the model too complex and not generalize well.\n",
        "\n",
        "There are mainly two types:\n",
        "\n",
        "L1 Regularization (Lasso): It can shrink some coefficients to 0.\n",
        "\n",
        "L2 Regularization (Ridge): It penalizes large weights but does not make them exactly zero.\n",
        "\n",
        "We need regularization so the model does not memorize training data and perform bad on testing data.\n",
        "\n",
        "Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "\n",
        "Answer:\n",
        "Some metrics are:\n",
        "\n",
        "Accuracy: Percent of correctly predicted samples.\n",
        "\n",
        "Precision: Out of predicted positive, how many are really positive.\n",
        "\n",
        "Recall (Sensitivity): Out of real positives, how many model predicted correctly.\n",
        "\n",
        "F1-score: Harmonic mean of precision and recall.\n",
        "\n",
        "ROC-AUC: Shows the ability of model to separate classes.\n",
        "\n",
        "These metrics are important because accuracy alone is not enough espically when data is imbalanced. Example: if 95% are negative and only 5% positive, a model can get 95% accuracy by always predicting negative but it is useless."
      ],
      "metadata": {
        "id": "vRSbeT4jv867"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 5: Python Program (Basic Logistic Regression)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_d7bLgzwBOl",
        "outputId": "205a0519-f865-4f68-b45d-8d621a4daf43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.956140350877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6: Logistic Regression with L2 Regularization\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbEqzATKwdKw",
        "outputId": "57542828-75e0-4922-e948-aca59c04b27d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [[ 2.09981182  0.13248576 -0.10346836 -0.00255646 -0.17024348 -0.37984365\n",
            "  -0.69120719 -0.4081069  -0.23506963 -0.02356426 -0.0854046   1.12246945\n",
            "  -0.32575716 -0.06519356 -0.02371113  0.05960156  0.00452206 -0.04277587\n",
            "  -0.04148042  0.01425051  0.96630267 -0.37712622 -0.05858253 -0.02395975\n",
            "  -0.31765956 -1.00443507 -1.57134711 -0.69351401 -0.84095566 -0.09308282]]\n",
            "Accuracy: 0.956140350877193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 7: Logistic Regression Multi-Class (OvR)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA_z9Uxywk1Y",
        "outputId": "67c3c493-a927-49a9-f7bf-1bc87b33d762"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: GridSearchCV for Hyperparameter Tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Best Score:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnA8GEz4wqtm",
        "outputId": "2d6c9fc5-8b04-469a-f5ef-13b42b336480"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Best Score: 0.9626373626373628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Standardization and Comparison\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Without scaling\n",
        "model1 = LogisticRegression(max_iter=1000)\n",
        "model1.fit(X_train, y_train)\n",
        "print(\"Accuracy without scaling:\", accuracy_score(y_test, model1.predict(X_test)))\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model2 = LogisticRegression(max_iter=1000)\n",
        "model2.fit(X_train_scaled, y_train)\n",
        "print(\"Accuracy with scaling:\", accuracy_score(y_test, model2.predict(X_test_scaled)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXdVHky5wwN0",
        "outputId": "e8f483be-6dee-4a38-ba44-7d4a49846d26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.956140350877193\n",
            "Accuracy with scaling: 0.9736842105263158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 10: Real-world Business Case (Imbalanced Data)\n",
        "Answer:\n",
        "If I was working in an ecommerce company with 5% response rate, I would handle it carefully.\n",
        "\n",
        "Steps I will follow:\n",
        "\n",
        "Data Handling: Clean missing values, encode categorical variables.\n",
        "\n",
        "Feature Scaling: Since logistic regression is sensitive to scale, I will use StandardScaler.\n",
        "\n",
        "Class Balancing: Because only 5% are positive, I would use oversampling (SMOTE) or undersampling or give class_weight='balanced' in logistic regression.\n",
        "\n",
        "Hyperparameter Tuning: Use GridSearchCV to find best penalty and C.\n",
        "\n",
        "Evaluation Metrics: Accuracy is not enough, I will check Precision, Recall, F1, ROC-AUC. Recall is more important here because we don’t want to miss customers who may respond.\n",
        "\n",
        "Finally I will deploy the model and monitor it regularly since customer behaviour changes with time."
      ],
      "metadata": {
        "id": "G1O-mUQmw4Gz"
      }
    }
  ]
}